{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import scipy.io as sio\n",
    "#from Lorenz96_RK4 import Lorenz96\n",
    "from L96_Model import L96\n",
    "import sys, os, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data, Data Assimilation Hyperparameters\n",
    "D = 20\n",
    "Dobs = 12\n",
    "dims = set(np.arange(20))\n",
    "#dim_obs = [1, 2, 3, 5, 7, 9, 11, 13, 15, 17, 18, 19]\n",
    "dim_obs = [0, 1, 2, 4, 6, 8, 10, 12, 14, 16, 17, 18]\n",
    "dim_unobs = list(dims - set(dim_obs))\n",
    "M = 200\n",
    "\n",
    "# Annealing Hyperparameters\n",
    "Rm = 1\n",
    "Rf0 = 1e6\n",
    "alpha = 1.3\n",
    "betamax = 3\n",
    "\n",
    "\n",
    "# Hamiltonian Monte Carlo Hyperparameters\n",
    "niter = int(1e2)\n",
    "Te = np.exp(1e-1*np.arange(niter))  # Temperature\n",
    "epsilon = 1e-3*np.ones(niter)\n",
    "L = 150\n",
    "mass = [1e3, 1e-2, 1e0]\n",
    "# Hamiltonian Monte Carlo Tuning Parameters\n",
    "mass_X = np.zeros(shape=(D,M))\n",
    "mass_X[dim_obs,:] = mass[0]\n",
    "mass_X[dim_unobs,:] = mass[1]\n",
    "mass_nu = mass[2]\n",
    "\n",
    "mass_X_sqrt = np.zeros(shape=(D,M))\n",
    "mass_X_sqrt[dim_obs,:] = np.sqrt(2*mass[0])\n",
    "mass_X_sqrt[dim_unobs,:] = np.sqrt(2*mass[1])\n",
    "mass_nu_sqrt = np.sqrt(2*mass[2])\n",
    "\n",
    "# Post-processing\n",
    "plot_Action_vs_beta = False\n",
    "savedata = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "gen_nu = \"8.17\"\n",
    "gen_noise = \"sig0.4\"\n",
    "gen_dt = \"0.001\"\n",
    "gen_delta_t = \"0.025\"\n",
    "gen_integrator = \"RK4\"\n",
    "\n",
    "# Specify the data path\n",
    "datapath = (\"./L96_D%s_nu%s_%s_dt%s_deltat%s_%s.mat\" % \n",
    "    (str(D), gen_nu, gen_noise, gen_dt, gen_delta_t, gen_integrator))\n",
    "\n",
    "if datapath[-3:] == \"mat\":\n",
    "    datadict = sio.loadmat(datapath)\n",
    "    data = datadict[\"Data\"]\n",
    "    dt = datadict[\"delta_t\"][0]\n",
    "elif datapath[-3:] == \"npy\":\n",
    "    data = np.load(datapath)\n",
    "else:\n",
    "    raise IOError (\"Does not recognize data file extension\\n datapath = %s\" % datapath)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "Y = data[dim_obs,:M]\n",
    "\n",
    "#Initialize the state variables\n",
    "nu_init = 8\n",
    "\n",
    "np.random.seed(12345)\n",
    "X_init = np.zeros((D,M))\n",
    "X_init[:,0] = 20*np.random.random(size=(D))\n",
    "X_init[dim_obs, :] = Y\n",
    "\n",
    "for k in range(0, M-1): # should be M -1??\n",
    "    X_init[:,k+1] = X_init[:,k] + dt *  L96(X_init[:,k]+dt/2*L96(X_init[:,k], nu_init),nu_init)\n",
    "    X_init[dim_obs,k+1] = Y[:,k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize vectorized dirac delta functions\n",
    "eyeDleft1 = np.roll(np.eye(D), -1, 1)\n",
    "eyeDleft2 = np.roll(np.eye(D),-2,1)\n",
    "eyeDright1 = np.roll(np.eye(D),1,1)\n",
    "eyeD = np.eye(D)\n",
    "# Some initializations for HMC\n",
    "\n",
    "# Define the Rf ladder\n",
    "Rf = Rf0 * (alpha**(np.arange(0,betamax)))\n",
    "\n",
    "# Initialize the solutions\n",
    "X_sol = X_init\n",
    "nu_sol = nu_init\n",
    "# Initialize the final output cell array. (It is a dict in order to replicate the cells data type in MATLAB)\n",
    "# This will contain the final X_sol for each beta, and nu_sol for eah beta\n",
    "q_min = {'X_min': np.zeros(shape=(D,M,betamax)), 'nu_min': np.zeros(shape=(betamax))}\n",
    "\n",
    "#Initialize action matrix\n",
    "Action = np.zeros(shape=(betamax, niter))  #in MATLAB code, the shape is (betamax, niter+1). Not sure why the +1\n",
    "Action_min = np.zeros(shape=(betamax,1))\n",
    "\n",
    "# Percentage acceptance and percentage downhill\n",
    "Acceptance = np.zeros(shape=(betamax,1))\n",
    "Downhill = np.zeros(shape=(betamax, 1))\n",
    "\n",
    "# Initialize Momentum\n",
    "pX0 = np.zeros(shape=(D,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start annealing for beta = 0 ...\n",
      "Done! Time elapsed: 0.67sec\n",
      "Start annealing for beta = 1 ...\n",
      "Done! Time elapsed: 0.67sec\n",
      "Start annealing for beta = 2 ...\n",
      "Done! Time elapsed: 0.69sec\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hamiltonian Monte Carlo Algorithm\n",
    "\n",
    "for beta in range(betamax):\n",
    "    # Initialize states (i.e. take the results from the previous step)\n",
    "    X0 = X_sol\n",
    "    X0[dim_obs,:] = Y  # Is this really necessary?\n",
    "    nu0 = nu_sol\n",
    "    \n",
    "    # Evaluate the starting action under current beta\n",
    "    Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX = fun_getPieces(X0, nu0, dt)\n",
    "    Action[beta, 1] = fun_A(X0, Xleft1, hX, Y, dim_obs, M, Rm, Rf[beta])\n",
    "    Action_min[beta] = Action[beta, 1]\n",
    "    \n",
    "    print(\"Start annealing for beta = %d ...\" % beta)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for n in range(1, niter):\n",
    "        eps = epsilon[n-1]\n",
    "        \n",
    "        # Take current q as starting point\n",
    "        X = X0\n",
    "        nu = nu0\n",
    "        \n",
    "        # Generate initial momenta from a multivariate normal distribution\n",
    "        pX0[dim_obs,:] = np.random.normal(0, np.sqrt(mass[0]), size=(Dobs,M))\n",
    "        pX0[dim_unobs,:] = np.random.normal(0, np.sqrt(mass[1]), size=(D-Dobs, M))\n",
    "        pnu0 = np.random.normal(0, np.sqrt(mass[2]))\n",
    "        \n",
    "        # Get necessary pieces\n",
    "        Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX = fun_getPieces(X0, nu0, dt)\n",
    "        # Half step for the X momenta\n",
    "        pX = pX0 - eps/2*fun_dAX(X, Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX, Y, eyeD, eyeDleft1, eyeDleft2, eyeDright1, D, dim_obs, M, dt, Rm, Rf[beta])\n",
    "        # Half step for the nu momentum\n",
    "        pnu = pnu0 - eps/2*fun_dAnu(Xleft1, Zup1, Zdown2, hX, M, dt, Rf[beta])\n",
    "        \n",
    "        # Calculate Action when simulation is done\n",
    "        Action_candidate = fun_A(X, Xleft1, hX, Y, dim_obs, M, Rm, Rf[beta])\n",
    "        # Metropolis-Hastings acceptance/rejection rule\n",
    "        if np.random.uniform() < np.exp((Action[beta, n] + np.sum(np.divide(pX0, mass_X_sqrt)**2) # is the index for n right here?\n",
    "                                        + (pnu0 / mass_nu_sqrt)**2 \n",
    "                                        - Action_candidate - np.sum(np.divide(pX, mass_X_sqrt)**2)\n",
    "                                       - (pnu/mass_nu_sqrt)**2 ) / Te[n]): # Check the temperature here\n",
    "            X0 = X\n",
    "            nu0 = nu\n",
    "            Action[beta, n] = Action_candidate\n",
    "            # Count acceptance rate\n",
    "            Acceptance[beta] += 1\n",
    "        else:\n",
    "            Action[beta, n] = Action[beta, n]\n",
    "            \n",
    "        # Check if the current proposal yields the lowest action so far\n",
    "        if Action[beta, n] < Action_min[beta]:\n",
    "            Action_min[beta] = Action[beta, n]\n",
    "            X_sol = X0\n",
    "            nu_sol = nu0\n",
    "            Downhill[beta] += 1\n",
    "            \n",
    "    print(\"Done! Time elapsed: %.2fsec\" % (time.time() - start_time))\n",
    "    \n",
    "    # Record argmin(A[:,beta]) for the current beta\n",
    "    q_min['X_min'][:,:,beta] = X_sol\n",
    "    q_min['nu_min'][beta] = nu_sol\n",
    "    \n",
    "    # Finalize these acceptances\n",
    "    Acceptance[beta] /= niter\n",
    "    Downhill[beta] /= niter\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1L, 20L, 200L)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.transpose(Xleft1[:,:,None] - hX[:,:,None], (0, 2, 1))\n",
    "T = np.ones((20,20,200))\n",
    "test1 = test * T\n",
    "test2 = np.sum(test1, 0)[None,:,:]\n",
    "test2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20L, 200L)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20L, 200L)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20L, 200L, 1L)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(kern1.shape, kern2.shape, kern3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer new variables and save useful variables\n",
    "Action_init = np.zeros(betamax)\n",
    "for beta in xrange(betamax):\n",
    "    Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX = fun_getPieces(X_init, nu_init, dt)\n",
    "    Action_init[beta] = fun_A(X_init, Xleft1, hX, Y, dim_obs, M, Rm, Rf[beta])\n",
    "    \n",
    "    \n",
    "ME = np.zeros(betamax)\n",
    "FE = np.zeros(betamax)\n",
    "for beta in xrange(betamax):\n",
    "    # Evaluate Measurement Error\n",
    "    ME[beta] = 1/(2*M) * np.sum((q_min['X_min'][dim_obs,:,beta] - Y)**2)\n",
    "    # Evaluate Model Error\n",
    "    Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX = fun_getPieces(q_min['X_min'][:,:,beta], q_min['nu_min'][beta], dt)\n",
    "    kern2 = Xleft1 - hX\n",
    "    FE[beta] = 1/(2*M) * np.sum((kern2[:,:M-1])) # M-1 intentional here?\n",
    "\n",
    "    \n",
    "mass_string = []\n",
    "for m in mass:\n",
    "    mass_string.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "if savedata == 1:\n",
    "    save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_dAX(X, Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX, Y, eyeD, eyeDleft1, eyeDleft2, eyeDright1, D, dim_obs, M, dt, Rm, Rf):\n",
    "    \n",
    "    GX = np.multiply(eyeDleft1[:,:,None], np.transpose(Xup1[:,:,None] - Xdown2[:,:,None], (0, 2, 1))) \n",
    "    + np.multiply(eyeDright1[:,:,None] - eyeDleft2[:,:,None], np.transpose(Xdown1[:,:,None], (0, 2, 1))) - eyeD[:,:,None]\n",
    "        \n",
    "    GZ = np.multiply(eyeDleft1[:,:,None], np.transpose(Zup1[:,:,None] - Zdown2[:,:,None], (0, 2, 1))) \n",
    "    + np.multiply(eyeDright1[:,:,None] - eyeDleft2[:,:,None], np.transpose(Zdown1[:,:,None], (0, 2, 1))) - eyeD[:,:,None]\n",
    "    \n",
    "    GZGX = np.zeros(shape=(D,D,M))\n",
    "    for i in xrange(M):\n",
    "        GZGX[:,:,k] = np.matmul(GZ[:,:,k] , GZ[:,:,k])\n",
    "    \n",
    "    T = eyeD[:,:,None] + dt*GZ + dt**2 / 2*GZGX\n",
    "    kern3 = -Rf/M * np.transpose(np.sum(np.transpose(Xleft1[:,:,None] - hX[:,:,None], (0, 2, 1)) * T,axis=0)[None,:,:], (1, 2, 0))\n",
    "    kern3[:,M-1] = 0 # What is this for?\n",
    "    \n",
    "    kern1 = np.zeros(shape=(D,M))\n",
    "    kern1[dim_obs,:] = Rm/M * (X[dim_obs,:] - Y)\n",
    "    \n",
    "    kern2 = Rf/M * (X - np.roll(hX, 0, 1))\n",
    "    kern2[:,1] = 0\n",
    "    \n",
    "    dAX = kern1 + kern2 + kern3[:,:,0]\n",
    "    return dAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_dAnu(Xleft1, Zup1, Zdown2, hX, M, dt, Rf):\n",
    "    kern = np.multiply(Xleft1 - hX, dt + dt**2/2*(Zup1 - Zdown2 - 1))\n",
    "    dAnu = -Rf/M * np.sum(kern)\n",
    "    \n",
    "    return dAnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_getPieces(X, nu, dt):\n",
    "    Xup1 = np.roll(X, -1, 0)\n",
    "    Xdown1 = np.roll(X, 1, 0)\n",
    "    Xdown2 = np.roll(X, 2, 0)\n",
    "    Xleft1 = np.roll(X, -1, 1)\n",
    "    \n",
    "    Z = X + dt/2* (np.multiply(Xup1 - Xdown2, Xdown1) - X + nu)\n",
    "    Zup1 = np.roll(Z, -1, 0)\n",
    "    Zdown1 = np.roll(Z, 1, 0)\n",
    "    Zdown2 = np.roll(Z, 2, 0)\n",
    "    \n",
    "    hX = X + dt * (np.multiply(Zup1 - Zdown2, Zdown1) - Z + nu)\n",
    "    \n",
    "    return Xup1, Xdown2, Xdown1, Xleft1, Zup1, Zdown2, Zdown1, hX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_A(X, Xleft1, hX, Y, dim_obs, M, Rm, Rf):\n",
    "    kern1 = Rm/(2*M) * np.sum((X[dim_obs,:] - Y)**2)\n",
    "    \n",
    "    kern2 = Xleft1 - hX\n",
    "    kern2 = Rf/(2*M) * np.sum(kern2[:,:M-1]**2) # Is this right? I feel like it's leaving out one column\n",
    "    \n",
    "    return kern1 + kern2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    \"\"\"\n",
    "        This function is optional, in case you do not want to use previous data\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            A numpy.array object of shape (D, steps)\n",
    "    \"\"\"\n",
    "    # Set the hyperparamters for generating the data\n",
    "    # stepsize = dt\n",
    "    stepsize = 0.01\n",
    "\n",
    "    # How many time points\n",
    "    steps = 1000\n",
    "\n",
    "    # Initial point\n",
    "    np.random.seed(123456)\n",
    "    D = 20\n",
    "    y0 = np.random.random(D)*3\n",
    "    t0 = 0\n",
    "    F = 8\n",
    "\n",
    "    sample = Lorenz96(y0, t0, D, F)\n",
    "    data = sample.generate(stepsize=stepsize, steps=steps, addNoise=True, noise_level=0.04)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
